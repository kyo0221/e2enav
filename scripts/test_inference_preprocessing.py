#!/usr/bin/env python3

import numpy as np
import cv2
import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from network import Network

def create_test_image(width=480, height=300):
    """ãƒ†ã‚¹ãƒˆç”¨ã®480x300ç”»åƒã‚’ä½œæˆ"""
    img = np.zeros((height, width, 3), dtype=np.uint8)
    
    # ã‚°ãƒªãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æç”»
    grid_size = 50
    for i in range(0, width, grid_size):
        cv2.line(img, (i, 0), (i, height), (100, 100, 100), 1)
    for i in range(0, height, grid_size):
        cv2.line(img, (0, i), (width, i), (100, 100, 100), 1)
    
    # ä¸­å¤®ã«èµ¤ã„å††ã‚’æç”»
    center_x, center_y = width // 2, height // 2
    cv2.circle(img, (center_x, center_y), 30, (0, 0, 255), -1)
    
    # æ–¹å‘ã‚’ç¤ºã™çŸ¢å°ã‚’æç”»
    cv2.arrowedLine(img, (center_x, center_y), (center_x, center_y - 50), (0, 255, 0), 3)
    
    # ã‚µã‚¤ã‚ºæƒ…å ±ã‚’æç”»
    cv2.putText(img, f'{width}x{height}', (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    
    return img

def test_inference_preprocessing():
    """æ¨è«–æ™‚ã®å‰å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ãƒ†ã‚¹ãƒˆé–‹å§‹: æ¨è«–æ™‚ç”»åƒå‰å‡¦ç†ï¼ˆä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ—ï¼‰")
    
    # ç•°ãªã‚‹ã‚µã‚¤ã‚ºã§ãƒ†ã‚¹ãƒˆ
    test_cases = [
        (480, 300, "standard_training_size"),
        (640, 480, "larger_image"),
        (320, 240, "smaller_image"),
        (224, 224, "exact_target_size")
    ]
    
    output_dir = "/tmp/inference_preprocessing_test"
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"ğŸ“ çµæœä¿å­˜å…ˆ: {output_dir}")
    
    for width, height, case_name in test_cases:
        print(f"\nğŸ“‹ Testing {case_name}: {width}x{height}")
        
        # ãƒ†ã‚¹ãƒˆç”»åƒä½œæˆ
        test_img = create_test_image(width, height)
        
        # æ¨è«–æ™‚å‰å‡¦ç†å®Ÿè¡Œ
        processed_tensor = Network.preprocess_image(test_img, target_size=(224, 224))
        
        # ãƒ†ãƒ³ã‚½ãƒ«ã‚’numpyé…åˆ—ã«æˆ»ã™ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
        processed_np = processed_tensor.squeeze(0).permute(1, 2, 0).numpy()
        processed_uint8 = (processed_np * 255).astype(np.uint8)
        
        print(f"  å…¥åŠ›ã‚µã‚¤ã‚º: {test_img.shape}")
        print(f"  å‡ºåŠ›ãƒ†ãƒ³ã‚½ãƒ«ã‚µã‚¤ã‚º: {processed_tensor.shape}")
        print(f"  å‡ºåŠ›ç”»åƒã‚µã‚¤ã‚º: {processed_uint8.shape}")
        
        # å‡¦ç†æ–¹æ³•ã‚’åˆ¤å®š
        if width >= 224 and height >= 224:
            x_start = (width - 224) // 2
            y_start = (height - 224) // 2
            print(f"  å‡¦ç†æ–¹æ³•: ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ— (ä½ç½®: {x_start}, {y_start})")
        else:
            print(f"  å‡¦ç†æ–¹æ³•: ãƒªã‚µã‚¤ã‚º")
        
        # å…ƒç”»åƒã‚’ä¿å­˜
        cv2.imwrite(os.path.join(output_dir, f"{case_name}_original.png"), test_img)
        
        # å‡¦ç†å¾Œç”»åƒã‚’ä¿å­˜
        cv2.imwrite(os.path.join(output_dir, f"{case_name}_processed.png"), processed_uint8)
        
        # ã‚µã‚¤ãƒ‰ãƒã‚¤ã‚µã‚¤ãƒ‰æ¯”è¼ƒç”»åƒã‚’ä½œæˆ
        if test_img.shape[0] != processed_uint8.shape[0]:
            # ã‚µã‚¤ã‚ºãŒç•°ãªã‚‹å ´åˆã¯å…ƒç”»åƒã‚’ãƒªã‚µã‚¤ã‚º
            original_resized = cv2.resize(test_img, (224, 224))
        else:
            original_resized = test_img
            
        comparison = np.hstack([original_resized, processed_uint8])
        cv2.putText(comparison, "Original", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(comparison, "Processed", (234, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.imwrite(os.path.join(output_dir, f"{case_name}_comparison.png"), comparison)
    
    print(f"\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†ï¼çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    print("\nğŸ“Š æœŸå¾…ã•ã‚Œã‚‹çµæœ:")
    print("  - 480x300: ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ— (x=128, y=38)")
    print("  - 640x480: ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ— (x=208, y=128)")
    print("  - 320x240: ãƒªã‚µã‚¤ã‚ºå‡¦ç†")
    print("  - 224x224: ãã®ã¾ã¾ä½¿ç”¨")

def test_training_consistency():
    """è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã®ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”„ ãƒ†ã‚¹ãƒˆ: è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã®ä¸€è²«æ€§")
    
    # è¨“ç·´æ™‚ã¨åŒã˜ç”»åƒã‚’ä½œæˆ
    test_img = create_test_image(480, 300)
    
    # æ¨è«–æ™‚å‰å‡¦ç†ï¼ˆä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ—ï¼‰
    inference_tensor = Network.preprocess_image(test_img, target_size=(224, 224))
    
    # è¨“ç·´æ™‚å‰å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆshift_sign=0.0ï¼‰
    from utils.dataset_augment import DatasetAugmenter
    augmenter = DatasetAugmenter(shift_signs=[0.0])
    training_processed = augmenter._apply_horizontal_crop(test_img, 0.0, target_size=(224, 224))
    
    print(f"  æ¨è«–æ™‚ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶: {inference_tensor.shape}")
    print(f"  è¨“ç·´æ™‚ç”»åƒå½¢çŠ¶: {training_processed.shape}")
    
    # è¨“ç·´æ™‚ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«å½¢å¼ã«å¤‰æ›
    training_tensor = (torch.from_numpy(training_processed)
                      .permute(2, 0, 1).float() / 255.0)
    training_tensor = training_tensor.unsqueeze(0)
    
    # å·®åˆ†ã‚’è¨ˆç®—
    diff = torch.abs(inference_tensor - training_tensor).mean()
    print(f"  å‰å‡¦ç†ã®å·®åˆ†ï¼ˆå¹³å‡çµ¶å¯¾èª¤å·®ï¼‰: {diff.item():.6f}")
    
    if diff.item() < 1e-6:
        print("  âœ… è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã®å‰å‡¦ç†ãŒä¸€è‡´ã—ã¦ã„ã¾ã™")
    else:
        print("  âŒ è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã®å‰å‡¦ç†ã«å·®ç•°ãŒã‚ã‚Šã¾ã™")

if __name__ == "__main__":
    import torch
    test_inference_preprocessing()
    test_training_consistency()